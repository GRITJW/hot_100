{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Module: 所有神经网络模块的基类，自定义模型须继承该类并实现 forward() 方法\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = MyModel()\n",
    "x = torch.randn(3, 4)\n",
    "print(model(x).shape)   # torch.Size([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Linear: 全连接层，对输入做仿射变换 y = xW^T + b，常用于 MLP 和特征映射\n",
    "fc = nn.Linear(in_features=8, out_features=4)\n",
    "x = torch.randn(2, 8)         # batch_size=2, 输入维度=8\n",
    "print(fc(x).shape)             # torch.Size([2, 4])\n",
    "print(fc.weight.shape)         # torch.Size([4, 8])  权重矩阵\n",
    "print(fc.bias.shape)           # torch.Size([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2921, -0.9721,  1.4376,  0.2225],\n",
      "        [-2.0049,  0.7560, -0.5912, -0.7228],\n",
      "        [-0.2031, -2.3174,  0.3512,  0.0733],\n",
      "        [-2.0049,  0.7560, -0.5912, -0.7228]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([4, 4])\n",
      "torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Embedding: 将离散 ID（整数）映射为稠密向量，本质是可学习的查找表，推荐系统核心组件\n",
    "emb = nn.Embedding(num_embeddings=10, embedding_dim=4)  # 词表大小10，向量维度4\n",
    "ids = torch.tensor([0, 3, 7, 3])                         # 输入 token ID\n",
    "print(emb(ids))\n",
    "print(emb(ids).shape)          # torch.Size([4, 4])\n",
    "print(emb.weight.shape)        # torch.Size([10, 4])  整张 embedding 表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Identity: 占位层，输出与输入完全相同，常用于条件性跳过某层或作为消融实验的替换层\n",
    "layer = nn.Identity()\n",
    "x = torch.randn(3, 5)\n",
    "print(torch.equal(layer(x), x))   # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 50])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([1, 8, 8, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Conv1d: 一维卷积，常用于序列/文本特征提取，输入形状 (N, C_in, L)\n",
    "conv1d = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "x = torch.randn(2, 16, 50)       # (batch=2, channels=16, length=50)\n",
    "print(conv1d(x).shape)            # torch.Size([2, 32, 50])\n",
    "\n",
    "\n",
    "# torch.nn.Conv2d: 二维卷积，图像特征提取的核心层，输入形状 (N, C_in, H, W)\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "x = torch.randn(2, 3, 32, 32)    # (batch=2, RGB=3, H=32, W=32)\n",
    "print(conv2d(x).shape)            # torch.Size([2, 64, 32, 32])\n",
    "\n",
    "\n",
    "# torch.nn.Conv3d: 三维卷积，用于视频或医学影像等体积数据，输入形状 (N, C_in, D, H, W)\n",
    "conv3d = nn.Conv3d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "x = torch.randn(1, 1, 8, 16, 16)\n",
    "print(conv3d(x).shape)            # torch.Size([1, 8, 8, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.ConvTranspose2d: 转置卷积（有时称反卷积），用于从低分辨率特征图生成更高分辨率特征图，\n",
    "# 常见于图像生成（GAN）、语义分割（U-Net 上采样路径）等任务\n",
    "up = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=2, stride=2)\n",
    "x = torch.randn(2, 64, 16, 16)   # 低分辨率特征图\n",
    "print(up(x).shape)                # torch.Size([2, 32, 32, 32])  空间分辨率翻倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n",
      "torch.Size([4, 64, 8, 8])\n",
      "torch.Size([2, 8, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.BatchNorm1d: 对小批量的一维（序列/特征）数据进行批标准化，减少内部协变量偏移\n",
    "bn1d = nn.BatchNorm1d(num_features=16)\n",
    "x = torch.randn(8, 16)            # (batch=8, features=16)\n",
    "print(bn1d(x).shape)              # torch.Size([8, 16])\n",
    "\n",
    "\n",
    "# torch.nn.BatchNorm2d: 对小批量的二维（图像）数据沿通道维度进行批标准化\n",
    "bn2d = nn.BatchNorm2d(num_features=64)\n",
    "x = torch.randn(4, 64, 8, 8)     # (N, C, H, W)\n",
    "print(bn2d(x).shape)              # torch.Size([4, 64, 8, 8])\n",
    "\n",
    "\n",
    "# torch.nn.BatchNorm3d: 对小批量的三维体积数据沿通道维度进行批标准化\n",
    "bn3d = nn.BatchNorm3d(num_features=8)\n",
    "x = torch.randn(2, 8, 4, 4, 4)\n",
    "print(bn3d(x).shape)              # torch.Size([2, 8, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 8, 8])\n",
      "torch.Size([4, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.GroupNorm: 分组归一化，将通道分成若干组后在组内归一化，不依赖 batch size，适合小 batch 场景\n",
    "gn = nn.GroupNorm(num_groups=4, num_channels=16)\n",
    "x = torch.randn(2, 16, 8, 8)     # (N, C, H, W)\n",
    "print(gn(x).shape)                # torch.Size([2, 16, 8, 8])\n",
    "\n",
    "\n",
    "# torch.nn.LayerNorm: 层归一化，对每个样本独立地在指定维度上归一化，Transformer 的标配\n",
    "ln = nn.LayerNorm(normalized_shape=16)\n",
    "x = torch.randn(4, 10, 16)        # (batch, seq_len, d_model)\n",
    "print(ln(x).shape)                # torch.Size([4, 10, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "torch.Size([2, 16, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.SyncBatchNorm: 跨多个 GPU 设备同步统计量的批归一化，用于多卡分布式训练以保证一致性\n",
    "# （通常通过 nn.SyncBatchNorm.convert_sync_batchnorm(model) 将普通 BN 转换）\n",
    "sync_bn = nn.SyncBatchNorm(num_features=16)\n",
    "# 在分布式环境下使用，单卡等价于 BatchNorm1d\n",
    "x = torch.randn(4, 16)\n",
    "print(sync_bn(x).shape)           # torch.Size([4, 16])\n",
    "\n",
    "\n",
    "# torch.nn.LocalResponseNorm: 局部响应归一化（LRN），在相邻通道间做归一化，来自早期 AlexNet\n",
    "lrn = nn.LocalResponseNorm(size=5)  # 在相邻 5 个通道内归一化\n",
    "x = torch.randn(2, 16, 8, 8)\n",
    "print(lrn(x).shape)               # torch.Size([2, 16, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 2.])\n",
      "tensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808])\n",
      "tensor([-0.9640, -0.7616,  0.0000,  0.7616,  0.9640])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.ReLU: 修正线性单元，逐元素计算 max(0, x)，最常用激活函数，缓解梯度消失\n",
    "relu = nn.ReLU()\n",
    "x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
    "print(relu(x))    # tensor([0., 0., 0., 1., 2.])\n",
    "\n",
    "\n",
    "# torch.nn.Sigmoid: 将任意实数压缩到 (0, 1)，常用于二分类输出层或注意力门控\n",
    "sigmoid = nn.Sigmoid()\n",
    "print(sigmoid(x))  # tensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808])\n",
    "\n",
    "\n",
    "# torch.nn.Tanh: 双曲正切函数，将输入压缩到 (-1, 1)，常用于 RNN 隐藏层或特征归一化\n",
    "tanh = nn.Tanh()\n",
    "print(tanh(x))    # tensor([-0.9640, -0.7616,  0.0000,  0.7616,  0.9640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 16, 16])\n",
      "torch.Size([2, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.MaxPool2d: 二维最大池化层，在每个窗口内取最大值，保留显著特征，常用于 CNN 下采样\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "x = torch.randn(2, 64, 32, 32)\n",
    "print(maxpool(x).shape)           # torch.Size([2, 64, 16, 16])  空间尺寸减半\n",
    "\n",
    "\n",
    "# torch.nn.AvgPool2d: 二维平均池化层，在每个窗口内取平均值，特征更平滑，常用于全局平均池化\n",
    "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "print(avgpool(x).shape)           # torch.Size([2, 64, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 4, 4])\n",
      "torch.Size([2, 64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.AdaptiveMaxPool2d: 二维自适应最大池化，自动计算步长使输出为指定空间尺寸，无需手动计算 kernel_size\n",
    "ada_max = nn.AdaptiveMaxPool2d(output_size=(4, 4))\n",
    "x = torch.randn(2, 64, 13, 13)   # 任意输入尺寸\n",
    "print(ada_max(x).shape)           # torch.Size([2, 64, 4, 4])\n",
    "\n",
    "\n",
    "# torch.nn.AdaptiveAvgPool2d: 二维自适应平均池化，当 output_size=(1,1) 时等价于全局平均池化（GAP）\n",
    "ada_avg = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "print(ada_avg(x).shape)           # torch.Size([2, 64, 1, 1])  每通道全局均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 2., 2., 2., 2., 2., 2., 0., 0.],\n",
      "        [2., 0., 0., 2., 0., 0., 2., 0., 0., 0.]])\n",
      "tensor(True)\n",
      "torch.Size([2, 8, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Dropout: 训练时以概率 p 随机将神经元置零，推理时自动关闭，防止过拟合\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "x = torch.ones(2, 10)\n",
    "print(dropout(x))                 # 约一半元素被置零（训练模式下）\n",
    "\n",
    "\n",
    "# torch.nn.Dropout2d: 以概率 p 随机将整个通道（特征图）置零，适用于二维卷积特征\n",
    "dropout2d = nn.Dropout2d(p=0.3)\n",
    "x = torch.ones(2, 8, 4, 4)\n",
    "print((dropout2d(x) == 0).any())  # True，有整通道被置零\n",
    "\n",
    "\n",
    "# torch.nn.Dropout3d: 以概率 p 随机将三维体积数据的整个通道置零，适用于三维卷积特征\n",
    "dropout3d = nn.Dropout3d(p=0.3)\n",
    "x = torch.ones(2, 8, 4, 4, 4)\n",
    "print(dropout3d(x).shape)         # torch.Size([2, 8, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([ 0.2052, -0.4694, -0.2883,  2.5144], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Parameter: 将张量包装为模块参数，注册后会出现在 model.parameters() 中并参与梯度更新\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(dim))  # 可学习参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.weight\n",
    "\n",
    "layer = CustomLayer(4)\n",
    "print(list(layer.parameters()))   # [Parameter containing: tensor([...], requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.ParameterList: 以列表方式存储多个 nn.Parameter，支持按索引访问，参数会被正确注册\n",
    "class MultiHeadWeights(nn.Module):\n",
    "    def __init__(self, n_heads, dim):\n",
    "        super().__init__()\n",
    "        self.weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(dim, dim)) for _ in range(n_heads)]\n",
    "        )\n",
    "\n",
    "m = MultiHeadWeights(4, 8)\n",
    "print(len(list(m.parameters())))  # 4\n",
    "\n",
    "\n",
    "# torch.nn.ParameterDict: 以字典方式存储多个 nn.Parameter，支持按名称访问，参数会被正确注册\n",
    "class GatedLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "            'gate': nn.Parameter(torch.randn(8)),\n",
    "            'bias': nn.Parameter(torch.zeros(8))\n",
    "        })\n",
    "\n",
    "g = GatedLayer()\n",
    "print(g.params['gate'].shape)     # torch.Size([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 27, 64])\n",
      "torch.Size([1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Unfold: 将输入图像按滑动窗口展开为列（im2col），是卷积运算的底层实现基础\n",
    "unfold = nn.Unfold(kernel_size=3, stride=1, padding=1)\n",
    "x = torch.randn(1, 3, 8, 8)      # (N, C, H, W)\n",
    "out = unfold(x)\n",
    "print(out.shape)                  # torch.Size([1, 27, 64])  27=3*3*3通道, 64=8*8个窗口\n",
    "\n",
    "\n",
    "# torch.nn.Fold: Unfold 的逆操作，将展开的列重新组合回特征图（叠加重叠区域）\n",
    "fold = nn.Fold(output_size=(8, 8), kernel_size=3, stride=1, padding=1)\n",
    "restored = fold(out)\n",
    "print(restored.shape)             # torch.Size([1, 3, 8, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Sequential: 有序容器，模块按传入构造函数的顺序依次前向执行，适合构建简单线性网络\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "x = torch.randn(4, 16)\n",
    "print(model(x).shape)             # torch.Size([4, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.ModuleList: 以列表方式存储子模块，参数会被正确注册，支持按索引访问和动态遍历\n",
    "layers = nn.ModuleList([nn.Linear(8, 8) for _ in range(4)])\n",
    "x = torch.randn(2, 8)\n",
    "for layer in layers:\n",
    "    x = layer(x)\n",
    "print(x.shape)                    # torch.Size([2, 8])\n",
    "\n",
    "\n",
    "# torch.nn.ModuleDict: 以字典方式存储子模块，支持按名称访问，适合条件分支网络结构\n",
    "experts = nn.ModuleDict({\n",
    "    'expert_a': nn.Linear(8, 4),\n",
    "    'expert_b': nn.Linear(8, 4),\n",
    "})\n",
    "x = torch.randn(2, 8)\n",
    "print(experts['expert_a'](x).shape)  # torch.Size([2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 16]) torch.Size([2, 4, 16])\n",
      "torch.Size([4, 10, 16]) torch.Size([2, 4, 16])\n",
      "torch.Size([4, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.RNN: 基础循环神经网络，对序列逐步处理隐藏状态，长序列存在梯度消失问题\n",
    "rnn = nn.RNN(input_size=8, hidden_size=16, num_layers=2, batch_first=True)\n",
    "x = torch.randn(4, 10, 8)         # (batch=4, seq_len=10, input=8)\n",
    "out, h_n = rnn(x)\n",
    "print(out.shape, h_n.shape)       # torch.Size([4, 10, 16]) torch.Size([2, 4, 16])\n",
    "\n",
    "\n",
    "# torch.nn.LSTM: 长短期记忆网络，引入遗忘/输入/输出门控制信息流，有效缓解长序列梯度消失\n",
    "lstm = nn.LSTM(input_size=8, hidden_size=16, num_layers=2, batch_first=True)\n",
    "out, (h_n, c_n) = lstm(x)\n",
    "print(out.shape, h_n.shape)       # torch.Size([4, 10, 16]) torch.Size([2, 4, 16])\n",
    "\n",
    "\n",
    "# torch.nn.GRU: 门控循环单元，参数量少于 LSTM，实践中效果相当，训练更快\n",
    "gru = nn.GRU(input_size=8, hidden_size=16, num_layers=2, batch_first=True)\n",
    "out, h_n = gru(x)\n",
    "print(out.shape)                   # torch.Size([4, 10, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16]) torch.Size([4, 16])\n",
      "torch.Size([4, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.LSTMCell: 单步 LSTM 单元，每次只处理一个时间步，适合需要手动控制时序逻辑的场景\n",
    "lstm_cell = nn.LSTMCell(input_size=8, hidden_size=16)\n",
    "x_t = torch.randn(4, 8)           # 单个时间步输入\n",
    "h_t = torch.zeros(4, 16)          # 初始隐藏状态\n",
    "c_t = torch.zeros(4, 16)          # 初始细胞状态\n",
    "h_t, c_t = lstm_cell(x_t, (h_t, c_t))\n",
    "print(h_t.shape, c_t.shape)       # torch.Size([4, 16]) torch.Size([4, 16])\n",
    "\n",
    "\n",
    "# torch.nn.GRUCell: 单步 GRU 单元，每次只处理一个时间步，灵活性与 LSTMCell 相同\n",
    "gru_cell = nn.GRUCell(input_size=8, hidden_size=16)\n",
    "h_t = torch.zeros(4, 16)\n",
    "h_t = gru_cell(x_t, h_t)\n",
    "print(h_t.shape)                   # torch.Size([4, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 64])\n",
      "torch.Size([4, 10, 10])\n",
      "torch.Size([4, 6, 64])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.MultiheadAttention: 多头注意力机制，Transformer 的核心组件，\n",
    "# 通过并行多组 Query-Key-Value 注意力捕获不同子空间的依赖关系\n",
    "mha = nn.MultiheadAttention(embed_dim=64, num_heads=8, batch_first=True)\n",
    "q = k = v = torch.randn(4, 10, 64)  # (batch=4, seq_len=10, d_model=64)\n",
    "attn_out, attn_weights = mha(q, k, v)\n",
    "print(attn_out.shape)             # torch.Size([4, 10, 64])\n",
    "print(attn_weights.shape)         # torch.Size([4, 10, 10])  注意力分数矩阵\n",
    "\n",
    "\n",
    "# torch.nn.Transformer: 完整的 Transformer 编解码器模型，包含 Encoder 和 Decoder 堆栈，\n",
    "# 适用于机器翻译、序列到序列生成等任务\n",
    "transformer = nn.Transformer(\n",
    "    d_model=64, nhead=8, num_encoder_layers=3, num_decoder_layers=3, batch_first=True\n",
    ")\n",
    "src = torch.randn(4, 10, 64)      # 编码器输入\n",
    "tgt = torch.randn(4, 6, 64)       # 解码器输入\n",
    "out = transformer(src, tgt)\n",
    "print(out.shape)                  # torch.Size([4, 6, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1667)\n",
      "tensor(0.3695)\n",
      "tensor(1.6748)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.MSELoss: 均方误差损失，计算预测值与真实值差的平方均值，常用于回归任务\n",
    "mse = nn.MSELoss()\n",
    "pred = torch.tensor([2.5, 3.0, 4.0])\n",
    "target = torch.tensor([3.0, 3.0, 3.5])\n",
    "print(mse(pred, target))          # tensor(0.1667)\n",
    "\n",
    "\n",
    "# torch.nn.BCELoss: 二元交叉熵损失，要求输入已经过 Sigmoid，用于二分类或多标签分类\n",
    "bce = nn.BCELoss()\n",
    "pred_sigmoid = torch.sigmoid(torch.tensor([0.8, -0.5, 1.2]))\n",
    "target_bin = torch.tensor([1.0, 0.0, 1.0])\n",
    "print(bce(pred_sigmoid, target_bin))   # 二元交叉熵值\n",
    "\n",
    "\n",
    "# torch.nn.NLLLoss: 负对数似然损失，要求输入为 log 概率（通常来自 LogSoftmax），用于多分类\n",
    "nll = nn.NLLLoss()\n",
    "log_probs = torch.log_softmax(torch.randn(4, 5), dim=1)\n",
    "labels = torch.tensor([0, 2, 1, 4])\n",
    "print(nll(log_probs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3333)\n",
      "tensor(0.0833)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.L1Loss: 绝对误差损失（MAE），对异常值鲁棒性优于 MSE，梯度在零点不连续\n",
    "l1 = nn.L1Loss()\n",
    "pred = torch.tensor([2.5, 3.0, 4.0])\n",
    "target = torch.tensor([3.0, 3.0, 3.5])\n",
    "print(l1(pred, target))           # tensor(0.3333)\n",
    "\n",
    "\n",
    "# torch.nn.SmoothL1Loss: 平滑 L1 损失（Huber Loss），误差小时近似 L2，误差大时近似 L1，\n",
    "# 兼顾稳定性与鲁棒性，常用于目标检测回归分支\n",
    "smooth_l1 = nn.SmoothL1Loss()\n",
    "print(smooth_l1(pred, target))    # 介于 L1 和 L2 之间的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6419)\n",
      "tensor(1.5229)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.CrossEntropyLoss: 交叉熵损失，内部融合了 LogSoftmax 和 NLLLoss，\n",
    "# 直接接受原始 logits（无需手动 softmax），多分类任务的首选损失函数\n",
    "ce = nn.CrossEntropyLoss()\n",
    "logits = torch.randn(4, 5)        # (batch=4, num_classes=5)  原始 logits\n",
    "labels = torch.tensor([0, 2, 1, 4])\n",
    "print(ce(logits, labels))\n",
    "\n",
    "# 支持类别权重（缓解样本不均衡问题）\n",
    "weights = torch.tensor([1.0, 1.0, 2.0, 1.0, 1.0])  # 对第2类赋予更高权重\n",
    "ce_weighted = nn.CrossEntropyLoss(weight=weights)\n",
    "print(ce_weighted(logits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.GaussianNLLoss: 高斯负对数似然损失，同时预测均值和方差，用于不确定性估计的回归任务\n",
    "gauss_nll = nn.GaussianNLLoss()\n",
    "mean_pred = torch.tensor([1.0, 2.0, 3.0])   # 预测均值\n",
    "var_pred  = torch.tensor([0.5, 1.0, 2.0])   # 预测方差（须为正）\n",
    "target    = torch.tensor([1.2, 1.8, 3.5])\n",
    "print(gauss_nll(mean_pred, target, var_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2480)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.PoissonNLLLoss: 泊松负对数似然损失，用于目标值为计数或事件率的回归任务（如推荐系统 CTR 预测）\n",
    "poisson_nll = nn.PoissonNLLLoss(log_input=True)  # log_input=True 表示输入已取 log\n",
    "log_rate = torch.tensor([0.5, 1.0, 2.0])         # log(λ) 预测值\n",
    "target   = torch.tensor([1.0, 2.0, 5.0])         # 实际计数\n",
    "print(poisson_nll(log_rate, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2407)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.BCEWithLogitsLoss: 将 Sigmoid 层与 BCELoss 合并，数值更稳定（利用 log-sum-exp 技巧），\n",
    "# 推荐优先使用此函数替代手动 Sigmoid + BCELoss\n",
    "bce_logits = nn.BCEWithLogitsLoss()\n",
    "logits = torch.tensor([2.0, -1.0, 0.5, -3.0])   # 原始 logits，无需提前 sigmoid\n",
    "target = torch.tensor([1.0,  0.0, 1.0,  0.0])\n",
    "print(bce_logits(logits, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4662)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.KLDivLoss: KL 散度损失，衡量预测概率分布与目标概率分布之间的 Kullback-Leibler 散度，\n",
    "# 要求输入为 log 概率，目标为概率，常用于知识蒸馏和变分自编码器（VAE）\n",
    "kl = nn.KLDivLoss(reduction='batchmean')\n",
    "log_pred = torch.log_softmax(torch.randn(4, 5), dim=1)  # 学生模型 log 概率\n",
    "target_dist = torch.softmax(torch.randn(4, 5), dim=1)   # 教师模型概率分布\n",
    "print(kl(log_pred, target_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6027)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.CosineEmbeddingLoss: 余弦相似度嵌入损失，label=1 时使两向量相似，label=-1 时推远，\n",
    "# 常用于学习度量表示（如双塔召回模型、句子相似度）\n",
    "cos_emb = nn.CosineEmbeddingLoss(margin=0.0)\n",
    "x1 = torch.randn(4, 8)           # 用户/query 向量\n",
    "x2 = torch.randn(4, 8)           # 物品/document 向量\n",
    "label = torch.tensor([1, -1, 1, -1])  # 1 表示正样本对，-1 表示负样本对\n",
    "print(cos_emb(x1, x2, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2750)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.HingeEmbeddingLoss: 合页嵌入损失，label=1 时直接取输入值，label=-1 时取 max(0, margin-x)，\n",
    "# 用于学习基于距离的嵌入（如 SVM 风格的度量学习）\n",
    "hinge_emb = nn.HingeEmbeddingLoss(margin=1.0)\n",
    "x = torch.tensor([0.8, 1.5, 0.3, 2.0])  # 距离值\n",
    "label = torch.tensor([1, -1, 1, -1])     # 1 表示相似，-1 表示不相似\n",
    "print(hinge_emb(x, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1333)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.MarginRankingLoss: 间隔排序损失，使正样本得分高于负样本至少 margin，\n",
    "# 常用于 Learning to Rank 排序任务和推荐系统 Pairwise 训练\n",
    "margin_rank = nn.MarginRankingLoss(margin=0.3)\n",
    "x1 = torch.tensor([0.9, 0.6, 0.8])   # 正样本得分\n",
    "x2 = torch.tensor([0.3, 0.7, 0.5])   # 负样本得分\n",
    "label = torch.ones(3)                  # 1 表示希望 x1 > x2\n",
    "print(margin_rank(x1, x2, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4683)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.TripletMarginLoss: 三元组间隔损失，目标是使 d(anchor, positive) + margin < d(anchor, negative)，\n",
    "# 用于度量学习（人脸识别、图文匹配），使相似样本距离更近、不相似样本距离更远\n",
    "triplet = nn.TripletMarginLoss(margin=1.0)\n",
    "anchor   = torch.randn(4, 8)\n",
    "positive = torch.randn(4, 8)    # 与 anchor 同类的样本\n",
    "negative = torch.randn(4, 8)    # 与 anchor 不同类的样本\n",
    "print(triplet(anchor, positive, negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.9956)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.CTCLoss: 连续时间分类损失（Connectionist Temporal Classification），\n",
    "# 用于序列到序列的学习任务（如语音识别、手写识别），无需输入与标签的精确对齐\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean')\n",
    "# log_probs: (T=序列长度, N=batch, C=类别数)\n",
    "log_probs = torch.log_softmax(torch.randn(20, 4, 10), dim=2)\n",
    "targets = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])  # 拼接的目标序列\n",
    "input_lengths  = torch.full((4,), 20, dtype=torch.long)  # 每个样本的输入长度\n",
    "target_lengths = torch.tensor([2, 2, 2, 2], dtype=torch.long)  # 每个样本的目标长度\n",
    "print(ctc(log_probs, targets, input_lengths, target_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9439)\n",
      "tensor(1.7488)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.MultiLabelSoftMarginLoss: 多标签分类损失，基于 Sigmoid 对每个类别独立计算交叉熵，\n",
    "# 允许一个样本同时属于多个类别\n",
    "ml_soft = nn.MultiLabelSoftMarginLoss()\n",
    "logits = torch.randn(4, 5)        # (batch=4, num_classes=5)\n",
    "target = torch.tensor([[1,0,1,0,0],[0,1,0,1,0],[1,1,0,0,0],[0,0,0,1,1]], dtype=torch.float)\n",
    "print(ml_soft(logits, target))\n",
    "\n",
    "\n",
    "# torch.nn.MultiLabelMarginLoss: 多标签合页损失，基于 margin 约束正类得分高于负类，\n",
    "# 相比 SoftMargin 版本对排序更敏感\n",
    "ml_margin = nn.MultiLabelMarginLoss()\n",
    "logits2 = torch.randn(2, 5)\n",
    "target2 = torch.tensor([[0, 2, -1, -1, -1],  # -1 表示忽略\n",
    "                         [1, 3,  4, -1, -1]], dtype=torch.long)\n",
    "print(ml_margin(logits2, target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2789)\n",
      "tensor(0.7076)\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.SoftMarginLoss: 二分类合页损失的软化版本，使用 log(1+exp(-y*x)) 替代硬 hinge，\n",
    "# 标签须为 +1 或 -1\n",
    "soft_margin = nn.SoftMarginLoss()\n",
    "logits = torch.tensor([1.5, -0.5, 2.0, -1.0])\n",
    "labels = torch.tensor([1.0, -1.0, 1.0, -1.0])\n",
    "print(soft_margin(logits, labels))\n",
    "\n",
    "\n",
    "# torch.nn.MultiMarginLoss: 多分类合页损失，约束正类得分比每个负类得分至少高出 margin，\n",
    "# 是线性 SVM 多分类目标函数的 PyTorch 实现\n",
    "multi_margin = nn.MultiMarginLoss(margin=1.0)\n",
    "logits = torch.randn(4, 5)        # (batch=4, num_classes=5)\n",
    "labels = torch.tensor([0, 2, 1, 4])\n",
    "print(multi_margin(logits, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
